{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiiXJ7K_fePG"
      },
      "source": [
        "# **Quick fix for nerfstudio demo colab, issue #1077**\n",
        "\n",
        "https://github.com/nerfstudio-project/nerfstudio/issues/1077\n",
        "\n",
        "Original notebook: https://colab.research.google.com/github/nerfstudio-project/nerfstudio/blob/main/colab/demo.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manually** switch to Python 3.7 fallback runtime:\n",
        "\n",
        "```\n",
        "Tools > Command palette > Use fallback runtime version\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Warning**: Only seems to work immediately after connecting to a runtime. If the runtime gets restarted by a script (e.g. condalab installation), one needs to disconnect and reconnect to a new runtime first.\n",
        "\n"
      ],
      "metadata": {
        "id": "uK5VuMU_ZT-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version\n",
        "\n",
        "# Should give 3.7.xx - if it doesn't, follow instruction above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB6Bof1LrAf3",
        "outputId": "57d85f17-c2b9-416e-f978-4b492b8691f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problematic code below** (condalab installation). This restarted the runtime, falling back to Python 3.8 by default, hence making the tiny cuda installation (compiled for Python 3.8) fail. Leave it commented out.\n",
        "\n"
      ],
      "metadata": {
        "id": "dq5RGbIGrZFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGr33zHaHak0"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1>Install Conda (requires runtime restart)</h1>\n",
        "\n",
        "# This restarted the runtime, falling back to Python 3.8 by default. Leave it commented out.\n",
        "\n",
        "#!pip install -q condacolab\n",
        "#import condacolab\n",
        "#condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9oyLHl8QfYwP"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1>Install Nerfstudio and Dependencies (~10 min)</h1>\n",
        "\n",
        "%cd /content/\n",
        "!pip install --upgrade pip\n",
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Installing TinyCuda\n",
        "%cd /content/\n",
        "!gdown \"https://drive.google.com/u/1/uc?id=1q8fuc-Mqiev5GTBTRA5UPgCaQDzuqKqj\" \n",
        "!pip install tinycudann-1.6-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# Installing COLMAP\n",
        "%cd /content/\n",
        "!conda install -c conda-forge colmap\n",
        "\n",
        "# Install nerfstudio\n",
        "%cd /content/\n",
        "# !pip install nerfstudio\n",
        "!pip install git+https://github.com/nerfstudio-project/nerfstudio.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "XVlMjsICu4ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "msVLprI4gRA4"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1> Downloading and Processing Data</h1>\n",
        "#@markdown <h3>Pick the preset scene or upload your own images/video</h3>\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "scene = '\\uD83D\\uDDBC poster' #@param ['ğŸ–¼ poster', 'ğŸšœ dozer', 'ğŸŒ„ desolation', 'ğŸ“¤ upload your images' , 'ğŸ¥ upload your own video', 'ğŸ”º upload Polycam data', 'ğŸ’½ upload your own Record3D data']\n",
        "scene = ' '.join(scene.split(' ')[1:])\n",
        "\n",
        "if scene == \"upload Polycam data\":\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    if len(uploaded.keys()) > 1:\n",
        "        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n",
        "    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n",
        "    !ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene == 'upload your own Record3D data':\n",
        "    display(HTML('<h3>Zip your Record3D folder, and upload.</h3>'))\n",
        "    display(HTML('<h3>More information on Record3D can be found <a href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\">here</a>.</h3>'))\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    record_3d_zipfile = preupload_datasets[0]\n",
        "    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n",
        "    custom_data_directory = glob.glob('/content/data/nerfstudio/custom_data/*')[0]\n",
        "    !ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene in ['upload your images', 'upload your own video']:\n",
        "    display(HTML('<h3>Select your custom data</h3>'))\n",
        "    display(HTML('<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>'))\n",
        "    display(HTML('<p/>Note: This may take time, especially on hires inputs, so we recommend to download dataset after creation.<p>'))\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    if scene == 'upload your images':\n",
        "        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n",
        "        %cd /content/data/nerfstudio/custom_data/raw_images\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    else:\n",
        "        %cd /content/data/nerfstudio/custom_data/\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    del uploaded\n",
        "    %cd /content/\n",
        "\n",
        "    if scene == 'upload your images':\n",
        "        !ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/\n",
        "    else:\n",
        "        video_path = preupload_datasets[0]\n",
        "        !ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/\n",
        "\n",
        "    scene = \"custom_data\"\n",
        "else:\n",
        "    %cd /content/\n",
        "    !ns-download-data nerfstudio --capture-name=$scene\n",
        "\n",
        "print(\"Data Processing Succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VoKDxqEcjmfC"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1>Set up and Start Viewer</h1>\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Install localtunnel\n",
        "# We are using localtunnel https://github.com/localtunnel/localtunnel but ngrok could also be used\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# Tunnel port 7007, the default for\n",
        "!rm url.txt 2> /dev/null\n",
        "get_ipython().system_raw('lt --port 7007 >> url.txt 2>&1 &')\n",
        "\n",
        "import time\n",
        "time.sleep(3) # the previous command needs time to write to url.txt\n",
        "\n",
        "\n",
        "with open('url.txt') as f:\n",
        "  lines = f.readlines()\n",
        "websocket_url = lines[0].split(\": \")[1].strip().replace(\"https\", \"wss\")\n",
        "# from nerfstudio.utils.io import load_from_json\n",
        "# from pathlib import Path\n",
        "# json_filename = \"nerfstudio/nerfstudio/viewer/app/package.json\"\n",
        "# version = load_from_json(Path(json_filename))[\"version\"]\n",
        "url = f\"https://viewer.nerf.studio/?websocket_url={websocket_url}\"\n",
        "print(url)\n",
        "print(\"You may need to click Refresh Page after you start training!\")\n",
        "from IPython import display\n",
        "display.IFrame(src=url, height=800, width=\"100%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m_N8_cLfjoXD"
      },
      "outputs": [],
      "source": [
        "#@markdown <h1>Start Training</h1>\n",
        "\n",
        "%cd /content\n",
        "if os.path.exists(f\"data/nerfstudio/{scene}/transforms.json\"):\n",
        "    !ns-train nerfacto --viewer.websocket-port 7007 nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4\n",
        "else:\n",
        "    display(HTML('<h3 style=\"color:red\">Error: Data processing did not complete</h3>'))\n",
        "    display(HTML('<h3>Please re-run `Downloading and Processing Data`, or view the FAQ for more info.</h3>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGt8ukG6Htg3",
        "outputId": "fa946890-c7d8-4e46-a54e-7231bc5a2059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2;36m[19:48:48]\u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split train.                                          \u001b]8;id=527413;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243595;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split test.                                           \u001b]8;id=109270;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464675;file:///content/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/usr/local/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading latest checkpoint from load_dir\n",
            "âœ… Done loading checkpoint from \n",
            "outputs/data-nerfstudio-poster/nerfacto/\u001b[1;36m2022\u001b[0m-\u001b[1;36m10\u001b[0m-29_192844/nerfstudio_models/step-\u001b[1;36m000014000.\u001b[0mckpt\n",
            "\u001b[1;32mCreating trajectory video\u001b[0m\n",
            "\u001b[2KğŸ¥ Rendering ğŸ¥ \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[31m0.14 fps\u001b[0m \u001b[33m11:47\u001b[0m\n",
            "\u001b[2K\u001b[32m(  â—   )\u001b[0m \u001b[33mSaving video\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \u001b[0m\u001b[32m ğŸ‰ ğŸ‰ ğŸ‰ Success ğŸ‰ ğŸ‰ ğŸ‰\u001b[0m\u001b[92m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
            "                                           \u001b[32mSaved video to renders/output.mp4\u001b[0m                                            \n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title # Render Video { vertical-output: true }\n",
        "#@markdown <h3>Export the camera path from within the viewer, then run this cell.</h3>\n",
        "#@markdown <h5>The rendered video should be at renders/output.mp4!</h5>\n",
        "\n",
        "\n",
        "base_dir = \"/content/outputs/data-nerfstudio-\" + scene + \"/nerfacto/\"\n",
        "training_run_dir = base_dir + os.listdir(base_dir)[0]\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<h3>Upload the camera path JSON.</h3>'))\n",
        "%cd $training_run_dir\n",
        "uploaded = files.upload()\n",
        "uploaded_camera_path_filename = list(uploaded.keys())[0]\n",
        "\n",
        "config_filename = training_run_dir + \"/config.yml\"\n",
        "camera_path_filename = training_run_dir + \"/\" + uploaded_camera_path_filename\n",
        "camera_path_filename = camera_path_filename.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n",
        "\n",
        "%cd /content/\n",
        "!ns-render --load-config $config_filename --traj filename --camera-path-filename $camera_path_filename --output-path renders/output.mp4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('nerfstudio')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}